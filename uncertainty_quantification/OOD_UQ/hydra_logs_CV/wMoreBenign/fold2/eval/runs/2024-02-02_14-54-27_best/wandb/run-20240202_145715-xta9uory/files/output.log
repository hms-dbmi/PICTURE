[2024-02-02 14:57:23,750][src.tasks.eval_task][INFO] - Instantiating trainer <pytorch_lightning.Trainer>
[2024-02-02 14:57:23,756][pytorch_lightning.utilities.rank_zero][INFO] - Multiprocessing is handled by SLURM.
[2024-02-02 14:57:23,758][pytorch_lightning.utilities.rank_zero][INFO] - GPU available: False, used: False
[2024-02-02 14:57:23,759][pytorch_lightning.utilities.rank_zero][INFO] - TPU available: False, using: 0 TPU cores
[2024-02-02 14:57:23,759][pytorch_lightning.utilities.rank_zero][INFO] - IPU available: False, using: 0 IPUs
[2024-02-02 14:57:23,759][pytorch_lightning.utilities.rank_zero][INFO] - HPU available: False, using: 0 HPUs
[2024-02-02 14:57:23,759][src.tasks.eval_task][INFO] - Logging hyperparameters!
[2024-02-02 14:57:23,766][src.tasks.eval_task][INFO] - Starting testing!
train: 281 patients, val: 141 patients, test: 141 patients, total: 563 patients
[2024-02-02 14:57:35,742][pytorch_lightning.utilities.rank_zero][INFO] - Restoring states from the checkpoint path at /n/data2/hms/dbmi/kyu/lab/shl968/pathology_uncertainty-main/hydra_logs_CV/wMoreBenign/fold0/train/runs/2024-01-31_13-28-33_best/uncertainty_vienna_CTransFeature_wMoreBenign_fold0/1p7k8pd0/checkpoints/epoch=19-step=2760.ckpt
[2024-02-02 14:57:35,771][pytorch_lightning.utilities.rank_zero][INFO] - Loaded model weights from checkpoint at /n/data2/hms/dbmi/kyu/lab/shl968/pathology_uncertainty-main/hydra_logs_CV/wMoreBenign/fold0/train/runs/2024-01-31_13-28-33_best/uncertainty_vienna_CTransFeature_wMoreBenign_fold0/1p7k8pd0/checkpoints/epoch=19-step=2760.ckpt
Testing DataLoader 0:   1%|▏         | 1/68 [00:00<00:22,  3.01it/s]
/home/shl968/.conda/envs/uncertainty/lib/python3.10/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 1000. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.






















Testing DataLoader 0:  99%|█████████▊| 67/68 [00:44<00:00,  1.51it/s]
/home/shl968/.conda/envs/uncertainty/lib/python3.10/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 993. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(






/n/data2/hms/dbmi/kyu/lab/shl968/pathology_uncertainty-main/src/models/uncertainty_module.py:625: UserWarning: No data for colormapping provided via 'c'. Parameters 'cmap' will be ignored
  ax1.scatter(embeddings_tsne[idxs, 0], embeddings_tsne[idxs, 1], c=class_colors[idxs], label=label, alpha=0.5, s=4, cmap="RdYlGn")
/home/shl968/.conda/envs/uncertainty/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: Torchmetrics v0.9 introduced a new argument class property called `full_state_update` that has
                not been set for this class (AUCPR). The property determines if `update` by
                default needs access to the full metric state. If this is not the case, significant speedups can be
                achieved and we recommend setting this to `False`.
                We provide an checking function
                `from torchmetrics.utilities import check_forward_no_full_state`
                that can be used to check if the `full_state_update=True` (old and potential slower behaviour,
                default for now) or if `full_state_update=False` can be used safely.
  warnings.warn(*args, **kwargs)
/home/shl968/.conda/envs/uncertainty/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: Metric `AUROC` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.
Testing DataLoader 0: 100%|██████████| 68/68 [1:22:34<00:00, 72.86s/it]
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
┃          Test metric          ┃         DataLoader 0          ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩
│           test/acc            │      0.9444207549095154       │
│     test/aleatoric_AUPRC      │      0.8403530716896057       │
│    test/aleatoric_AUPRC_0     │      0.8488133549690247       │
│    test/aleatoric_AUPRC_1     │      0.05122857168316841      │
│ test/aleatoric_AUPRC_MacroAvg │      0.45002096332609653      │
│     test/aleatoric_AUROC      │      0.8806183338165283       │
│    test/aleatoric_AUROC_0     │      0.9003949761390686       │
│    test/aleatoric_AUROC_1     │      0.5445663928985596       │
│ test/aleatoric_AUROC_MacroAvg │      0.7224806845188141       │
│   test/aleatoric_confidence   │      0.40683549642562866      │
│           test/auc            │      0.9027228355407715       │
│       test/brier_score        │      0.1833496391773224       │
│    test/calibration_metric    │      0.8636490106582642       │
│     test/epistemic_AUPRC      │       0.842995285987854       │
│    test/epistemic_AUPRC_0     │      0.8509442806243896       │
│    test/epistemic_AUPRC_1     │      0.05440029129385948      │
│ test/epistemic_AUPRC_MacroAvg │      0.45267228595912457      │
│     test/epistemic_AUROC      │      0.8906292915344238       │
│    test/epistemic_AUROC_0     │      0.9076567888259888       │
│    test/epistemic_AUROC_1     │       0.601291298866272       │
│ test/epistemic_AUROC_MacroAvg │      0.7544740438461304       │
│   test/epistemic_confidence   │      0.5895354151725769       │
│           test/loss           │      0.38120248913764954      │
└───────────────────────────────┴───────────────────────────────┘
[2024-02-02 16:20:11,009][src.utils.utils][INFO] - Closing loggers...
[2024-02-02 16:20:11,010][src.utils.utils][INFO] - Closing wandb!